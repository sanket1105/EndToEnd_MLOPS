{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandatory Reading before the notebook\n",
    "        -- https://medium.com/@guptaguptalokesh2002/function-and-power-transformer-in-ml-c5a10e011f4d#:~:text=It%20is%20a%20feature%20transformation,data%20more%20suitable%20for%20modeling.\n",
    "\n",
    "        -- https://www.geeksforgeeks.org/data-pre-processing-wit-sklearn-using-standard-and-minmax-scaler/\n",
    "\n",
    "        -- https://proclusacademy.com/blog/robust-scaler-outliers/\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = Path(os.path.abspath(\"\"))\n",
    "with open(current_directory / \"config.yaml\") as f:\n",
    "    documents = yaml.full_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general = documents.get(\"general\")\n",
    "verbose = general.get(\"verbose\")\n",
    "\n",
    "# environment parameters\n",
    "env = documents.get(\"environment\")\n",
    "output_folder = env.get(\"output_folder\")\n",
    "input_path = Path(output_folder) / \"01_Initial_Data_Prep\"\n",
    "output_path = Path(output_folder) / \"02_Feature_Selection\"\n",
    "\n",
    "# feature selection parameters\n",
    "feature_selection = documents.get(\"feature_selection\")\n",
    "transformations = feature_selection.get(\"transformations\")\n",
    "transformation_evaluation = feature_selection.get(\"transformation_evaluation\")\n",
    "transformation_sig = feature_selection.get(\"transformation_significance\")\n",
    "vif_na_method = feature_selection.get(\"vif_na_method\")\n",
    "vif_threshold = feature_selection.get(\"vif_threshold\")\n",
    "kbins_params = feature_selection.get(\"kbins_params\")\n",
    "feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Utils import low_variance\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    f\"{Path(output_folder)}/01_Initial_Data_Prep/training_sampled_data.csv\"\n",
    ")\n",
    "perf_data = pd.read_csv(\n",
    "    f\"{Path(output_folder)}/01_Initial_Data_Prep/performance_sampled_data.csv\"\n",
    ")\n",
    "train_data, perf_data, cols_removed = low_variance(train_data, perf_data, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(f\"{output_path}/training_sampled_data_low_variance.csv\", index=False)\n",
    "perf_data.to_csv(\n",
    "    f\"{output_path}/performance_sampled_data_low_variance.csv\", index=False\n",
    ")\n",
    "\n",
    "\n",
    "with open(f\"{output_path}/low_variance_columns.txt\", \"w\") as f:\n",
    "    for col in cols_removed:\n",
    "        f.write(f\"{col}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:, :-1]\n",
    "X_test = perf_data.iloc[:, :-1]\n",
    "y_train = train_data.target\n",
    "y_test = perf_data.target\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{output_path}/y_train.csv\")\n",
    "y_test.to_csv(f\"{output_path}/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations\n",
    "\n",
    "        -- Removing the low variance cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{input_path}/numeric_columns.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "numeric_cols = [x.replace(\"\\n\", \"\") for x in lines]\n",
    "\n",
    "numeric_cols = list(set(numeric_cols) - set(cols_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import test_normality\n",
    "\n",
    "test_normality(X_train, numeric_cols)\n",
    "\n",
    "## since all the tests show no columns have normality, we are good now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import warnings\n",
    "original_warning_state = warnings.filters[:]\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from GenerateTransformations import DataTransformer\n",
    "\n",
    "X_train_transformed, X_test_transformed, trans_objects, trans_details = DataTransformer(\n",
    "    train=X_train,\n",
    "    valid=X_test,\n",
    "    cols=numeric_cols,\n",
    "    transformations=transformations\n",
    ").run()\n",
    "\n",
    "warnings.filters = original_warning_state\n",
    "X_train_transformed.shape, X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.to_parquet(\n",
    "    f\"{output_path}/X_train_transformed.parquet\", index=False\n",
    ")\n",
    "X_test_transformed.to_parquet(f\"{output_path}/X_test_transformed.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for k, v in trans_objects.items():\n",
    "    with open(f\"{output_path}/transformer_{k}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def convert_ndarray(obj):\n",
    "    \"\"\"Recursively convert ndarray objects in dict to lists\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_ndarray(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_ndarray(element) for element in obj]\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()  # Convert NumPy arrays to lists\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "# Convert all NumPy arrays in trans_details\n",
    "trans_details_serializable = convert_ndarray(trans_details)\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "with open(f\"{output_path}/transformer_details.json\", \"w\") as outfile:\n",
    "    json.dump(trans_details_serializable, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "trans_score_df = pd.DataFrame(data=numeric_cols, columns=[\"features\"])\n",
    "trans_score_df.set_index(\"features\", inplace=True)\n",
    "trans_score_df[\"nominal\"] = np.nan\n",
    "for t in transformations:\n",
    "    trans_score_df[t] = np.nan\n",
    "\n",
    "trans_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from EvaluateTransformation import TransformationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    test_features = [col + \"_\" + x for x in transformations]\n",
    "    test_features = [col + \"_nominal\"] + test_features\n",
    "    for f in test_features:\n",
    "        try:\n",
    "            score = TransformationEvaluator(X_train_transformed.loc[:,[f]], y_train, transformation_evaluation).run()\n",
    "        except np.linalg.LinAlgError:\n",
    "            score = -1\n",
    "        feat_name = col\n",
    "        transformation_name = f.replace(feat_name + \"_\", \"\")\n",
    "        trans_score_df.loc[feat_name, transformation_name] = score\n",
    "        \n",
    "warnings.filterwarnings(\"default\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"default\", category=RuntimeWarning)\n",
    "trans_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_score_df = abs(trans_score_df)\n",
    "trans_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_score_df[\"transformation\"] = trans_score_df.idxmax(axis=1)\n",
    "trans_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_score_df.transformation.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from Utils import transformation_significance\n",
    "trans_score_df = transformation_significance(X_train_transformed, trans_score_df, transformation_sig, verbose)\n",
    "trans_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_score_df.transformation_override.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = []\n",
    "for col in numeric_cols:\n",
    "    for t in transformations + [\"nominal\"]:\n",
    "        all_cols.append(col + \"_\" + t)\n",
    "\n",
    "non_transformed_cols = [\n",
    "    col for col in X_train_transformed.columns if col not in all_cols\n",
    "]\n",
    "non_transformed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_transformations = trans_score_df.reset_index()[\n",
    "    [\"features\", \"transformation_override\"]\n",
    "].agg(\"_\".join, axis=1)\n",
    "selected_transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_features = non_transformed_cols + list(selected_transformations)\n",
    "len(anova_features)\n",
    "\n",
    "## 2,462: matching with the original shape of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_path}/anova_columns.txt\", \"w\") as f:\n",
    "    for item in anova_features:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train_transformed.loc[:, anova_features]\n",
    "X_test_scaled = X_test_transformed.loc[:, anova_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.to_csv(f\"{output_path}/X_train_scaled_anova.csv\", index=False)\n",
    "X_test_scaled.to_csv(f\"{output_path}/X_test_scaled_anova.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Up Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory\n",
    "import sys\n",
    "\n",
    "\n",
    "def sizeof_fmt(num, suffix=\"B\"):\n",
    "    for unit in [\"\", \"Ki\", \"Mi\", \"Gi\", \"Ti\", \"Pi\", \"Ei\", \"Zi\"]:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, \"Yi\", suffix)\n",
    "\n",
    "\n",
    "for name, size in sorted(\n",
    "    ((name, sys.getsizeof(value)) for name, value in list(locals().items())),\n",
    "    key=lambda x: -x[1],\n",
    ")[:15]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data, perf_data, X_train, X_test, X_train_transformed, X_test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vif = X_train_scaled.copy(deep=True)\n",
    "X_test_vif = X_test_scaled.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vif.shape, X_test_vif.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIF\n",
    "-- This is taking some insane amount of time, almost met the god during its execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from ReduceVif import ReduceVIF\n",
    "# X_train_vif, final_vif = ReduceVIF(data=X_train_vif.iloc[:,1:], threshold=vif_threshold, verbose=verbose).run()\n",
    "\n",
    "# ## not letting the lg-seq-index to be part of this\n",
    "# ## to get the custloc: we will use the lg-seq-index to get from the data from EDA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from Utils import remove_correlated\n",
    "\n",
    "X_train_vif, one_unique_feature, to_drop = remove_correlated(X_train_vif.iloc[:,1:], threshold = 0.90)\n",
    "len(to_drop),len(one_unique_feature), X_train_vif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_features = X_train_vif.columns\n",
    "vif_features = [\"lg_seq_index\"] + list(\n",
    "    vif_features\n",
    ")  # if running the VIF, then this line needs to be executed, else no\n",
    "vif_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_path}/vif_columns.txt\", \"w\") as f:\n",
    "    for item in vif_features:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(f\"{output_path}/one_unique_value_feature.txt\", \"w\") as f:\n",
    "    for item in one_unique_feature:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vif_selected = X_train_scaled.loc[:, vif_features]\n",
    "X_test_vif_selected = X_test_scaled.loc[:, vif_features]\n",
    "\n",
    "X_train_vif_selected.fillna(-1, inplace=True)\n",
    "X_test_vif_selected.fillna(-1, inplace=True)\n",
    "X_train_vif_selected.isna().sum().sum(), X_test_vif_selected.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vif_selected.to_csv(f\"{output_path}/X_train_vif.csv\", index=False)\n",
    "X_test_vif_selected.to_csv(f\"{output_path}/X_test_vif.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this part is more manual and up to developer to use best judgements. The default implementations to use are below. They can be changed and merely act as a starting point. Depending on outputs, select features that are in n+ number of models\n",
    "- boruta\n",
    "- anova (via kbest)\n",
    "- recursive\n",
    "- extratree\n",
    "- lasso (via logistic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1, max_depth=5, random_state=0)\n",
    "boruta_feature_selector = BorutaPy(\n",
    "    clf, n_estimators=100, random_state=42, verbose=2, max_iter=50, perc=50\n",
    ")\n",
    "# boruta_feature_selector.fit(X_train_kbins.iloc[:,3:].values, y_train.values)\n",
    "boruta_feature_selector.fit(X_train_vif_selected.iloc[:, 1:].values, y_train.values)\n",
    "\n",
    "## not using lg-seq-index again for obvious reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boruta_features = X_train_kbins.iloc[:,3:].iloc[:,np.where(boruta_feature_selector.support_)[0]].columns\n",
    "boruta_features = (\n",
    "    X_train_vif_selected.iloc[:, 1:]\n",
    "    .iloc[:, np.where(boruta_feature_selector.support_)[0]]\n",
    "    .columns\n",
    ")\n",
    "len(boruta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=100)\n",
    "# selector.fit(X_train_kbins.iloc[:,3:].values, y_train)\n",
    "selector.fit(X_train_vif_selected.iloc[:, 1:].values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova_features = X_train_kbins.iloc[:,3:].iloc[:,selector.get_support(indices=True)].columns\n",
    "anova_features = (\n",
    "    X_train_vif_selected.iloc[:, 1:].iloc[:, selector.get_support(indices=True)].columns\n",
    ")\n",
    "len(anova_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(selector.scores_, columns=[\"ANOVA\"], index=X_train_kbins.iloc[:, 3:].columns).sort_values(\n",
    "#     by=\"ANOVA\", ascending=False\n",
    "# ).head(10)\n",
    "pd.DataFrame(\n",
    "    selector.scores_, columns=[\"ANOVA\"], index=X_train_vif_selected.iloc[:, 1:].columns\n",
    ").sort_values(by=\"ANOVA\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lg = LogisticRegression(solver=\"sag\", n_jobs=-1)\n",
    "rfe = RFE(lg, n_features_to_select=100, step=10, verbose=1)\n",
    "# rfe.fit(X_train_kbins.iloc[:,3:].values, y_train)\n",
    "rfe.fit(X_train_vif_selected.iloc[:, 1:].values, y_train)\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursive_features = X_train_kbins.iloc[:,3:].iloc[:,np.where(rfe.support_)[0]].columns\n",
    "recursive_features = (\n",
    "    X_train_vif_selected.iloc[:, 1:].iloc[:, np.where(rfe.support_)[0]].columns\n",
    ")\n",
    "len(recursive_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=50, n_jobs=-1, verbose=1)\n",
    "# clf.fit(X_train_kbins.iloc[:,3:].values, y_train)\n",
    "clf.fit(X_train_vif_selected.iloc[:, 1:].values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance_norm = np.std(\n",
    "    [tree.feature_importances_ for tree in clf.estimators_], axis=0\n",
    ")\n",
    "# extra_tree_features = X_train_kbins.iloc[:,3:].iloc[:,[feat_importance_norm > np.mean(feat_importance_norm)][0]]\n",
    "extra_tree_features = X_train_vif_selected.iloc[:, 1:].iloc[\n",
    "    :, [feat_importance_norm > np.mean(feat_importance_norm)][0]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Lasso\n",
    "lasso = LogisticRegression(penalty=\"l1\", C=0.5, solver=\"saga\")\n",
    "# lasso.fit(X_train_kbins.iloc[:,3:].values, y_train)\n",
    "lasso.fit(X_train_vif_selected.iloc[:, 1:].values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso_features = X_train_kbins.iloc[:,3:].iloc[:,(lasso.coef_ > 0)[0]]\n",
    "lasso_features = X_train_vif_selected.iloc[:, 1:].iloc[:, (lasso.coef_ > 0)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_selected_features = pd.DataFrame(data=X_train_kbins.columns, columns=[\"features\"])\n",
    "df_selected_features = pd.DataFrame(\n",
    "    data=X_train_vif_selected.columns, columns=[\"features\"]\n",
    ")\n",
    "df_selected_features[\"boruta\"] = df_selected_features.features.isin(boruta_features)\n",
    "df_selected_features[\"anova\"] = df_selected_features.features.isin(anova_features)\n",
    "df_selected_features[\"recursive\"] = df_selected_features.features.isin(\n",
    "    recursive_features\n",
    ")\n",
    "df_selected_features[\"extra_tree\"] = df_selected_features.features.isin(\n",
    "    extra_tree_features\n",
    ")\n",
    "df_selected_features[\"lasso\"] = df_selected_features.features.isin(lasso_features)\n",
    "df_selected_features[\"num_models\"] = df_selected_features[\n",
    "    [\"boruta\", \"anova\", \"recursive\", \"extra_tree\", \"lasso\"]\n",
    "].sum(axis=1)\n",
    "df_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_features.num_models.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_features[df_selected_features.num_models == 4].features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_model_count = 3\n",
    "# selected_features = (\n",
    "#     X_train_kbins.iloc[:, :3].columns.tolist()\n",
    "#     + df_selected_features[\n",
    "#         df_selected_features.num_models >= min_model_count\n",
    "#     ].features.tolist()\n",
    "# )\n",
    "selected_features = (\n",
    "    X_train_vif_selected.iloc[\n",
    "        :, :1\n",
    "    ].columns.tolist()  # just first column and features that occured in more than equal 3 methods\n",
    "    + df_selected_features[\n",
    "        df_selected_features.num_models >= min_model_count\n",
    "    ].features.tolist()\n",
    ")\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_path}/selected_columns.txt\", \"w\") as f:\n",
    "    for item in selected_features:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_selected = X_train_kbins.loc[:, selected_features]\n",
    "# X_valid_selected = X_valid_kbins.loc[:, selected_features]\n",
    "X_train_selected = X_train_vif_selected.loc[:, selected_features]\n",
    "X_test_selected = X_test_vif_selected.loc[:, selected_features]\n",
    "X_train_selected.shape, X_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected.to_csv(f\"{output_path}/X_train_selected.csv\", index=False)\n",
    "X_test_selected.to_csv(f\"{output_path}/X_test_selected.csv\", index=False)\n",
    "# TODO: add step for y_test and train to be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bin Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optional step to use odds ratio...add more commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected.shape, X_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "binning_cols = [x for x in selected_transformations if x in selected_features]\n",
    "non_binning_cols = [x for x in non_transformed_cols if x in selected_features]\n",
    "\n",
    "# X_train_binning = X_train_selected.loc[:, binning_cols]\n",
    "# X_train_non_binning = X_train_selected.loc[:, non_binning_cols]\n",
    "# X_test_binning = X_test_selected.loc[:, binning_cols]\n",
    "# X_test_non_binning = X_test_selected.loc[:, non_binning_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(binning_cols), len(non_binning_cols), X_train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in binning_cols:\n",
    "    if i not in selected_features:\n",
    "        binning_cols.remove(i)\n",
    "\n",
    "for i in non_binning_cols:\n",
    "    if i not in selected_features:\n",
    "        non_binning_cols.remove(i)\n",
    "\n",
    "len(binning_cols), len(non_binning_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all valid\n",
    "%time\n",
    "from BinData import BinData\n",
    "\n",
    "X_train_kbins, X_test_kbins, kbins_est = BinData(\n",
    "    X_train=X_train_selected,\n",
    "    X_valid=X_test_selected,\n",
    "    binning_cols=binning_cols,\n",
    "    non_binning_cols=non_binning_cols,\n",
    "    n_bins=kbins_params[\"n_bins\"],\n",
    "    bin_encoding=kbins_params[\"bin_encoding\"],\n",
    "    bin_strategy=kbins_params[\"bin_strategy\"],\n",
    "    output_path=output_path,\n",
    ").run()\n",
    "\n",
    "X_train_kbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_path}/kbins_discretizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(kbins_est, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_kbins.to_csv(f\"{output_path}/X_train_kbins.csv\", index=False)\n",
    "X_test_kbins.to_csv(f\"{output_path}/X_test_kbins.csv\", index=False)\n",
    "X_train_kbins.shape, X_test_kbins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optional step to try data reductions...add more commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PCAData import ReduceData\n",
    "\n",
    "X_train_reduced, pca, _ = ReduceData(\n",
    "    data=X_train_selected.iloc[:, 1:].values, var=0.95\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_path}/pca.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = pd.concat(\n",
    "    [X_train_selected.iloc[:, :1], pd.DataFrame(X_train_reduced)], axis=1\n",
    ")\n",
    "X_test_reduced = pd.concat(\n",
    "    [\n",
    "        X_test_selected.iloc[:, :1],\n",
    "        pd.DataFrame(pca.transform(X_test_selected.iloc[:, 1:].values)),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "X_train_reduced.shape, X_test_reduced.shape  # TODO: check why sizes different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced.to_csv(f\"{output_path}/X_train_reduced.csv\", index=False)\n",
    "X_test_reduced.to_csv(f\"{output_path}/X_test_reduced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_perf = pd.read_csv(f\"{Path(output_folder)}/01_Initial_Data_Prep/X_perf.csv\")\n",
    "# y_perf = pd.read_csv(f\"{Path(output_folder)}/01_Initial_Data_Prep/y_perf.csv\")\n",
    "# X_perf.shape, y_perf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from build_performance import BuildPerformance\n",
    "\n",
    "# X_perf_selected = BuildPerformance(\n",
    "#     X=X_perf,\n",
    "#     transformations=selected_transformations,\n",
    "#     scalers=scalers,\n",
    "#     vif_cols=vif_features,\n",
    "#     nan_replacements=null_dict,\n",
    "#     bin_cols=binning_cols,\n",
    "#     kbins_est=kbins_est,\n",
    "#     kbins_df_cols=X_train_kbins.columns.tolist(),\n",
    "#     selected_features=selected_features,\n",
    "#     X_train=X_train, # temp\n",
    "# ).run()\n",
    "# X_perf_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_perf_selected.to_csv(f\"{output_path}/X_perf_selected.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_perf_reduced = pd.concat(\n",
    "#     [X_valid_selected.iloc[:, :3], pd.DataFrame(pca.transform(X_perf_selected.iloc[:, 3:].values))], axis=1\n",
    "# )\n",
    "# X_perf_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_perf_reduced.to_csv(f\"{output_path}/X_perf_reduced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
